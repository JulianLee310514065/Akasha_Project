# Akasha(大新聞計畫)
### 契機

### 爬蟲系統
* **爬蟲** : 使用爬蟲程式爬取美國、中國、台灣、韓國約40~50個網站，並使用Google翻譯API將外語翻成中文。
* **SQL** : 使用MySQL做為資料儲存的工具，以供查詢及未來NLP訓練使用，目前各語言約有150萬則新聞(一年半)。
* **Telegram** : 由於不會時時刻刻看著電腦，所以當重要的新聞或是重要的關鍵字出現，會將其透過Telegram API送至Telegram，讓我們可以第一時間透過Telegram得知重要的新聞，諸如紅海事件、中國爆發流感等等的突發事件，早一小時甚至一分鐘知道也許就能提早應對(進場)。
* **GUI** : 重要的新聞會想存下來之後看，或是編寫自己的意見，或是給其加上tag，抑或是想查詢關鍵字等等，但是直接用SQL Syntax可能有點麻煩，且並不適合給不會程式的人操作，因此GUI就成了重要的工具。
* **NLP** : 剛剛提到新聞量很多，但其中有不少相關甚至重複的新聞，畢竟如果是重要的新聞各大新聞網絕對會搶著報，所以刪除重複就是我們想做的，之後也希望可以做新聞的自動分類或是提取關鍵字並依照頻率做出文字雲等等，但目前仍在開發中。

### 資金流與市場動向


# Repocitry Dir
1. Web_Scrapy 使用requests與selenium去獲取網站資訊
2. MySQL 結合DB可以將爬到的資料作儲存
3. GUI 搭配GUI以做到新聞編輯、我的最愛、標籤或是搜尋等功能
